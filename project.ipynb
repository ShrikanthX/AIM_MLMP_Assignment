{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Assignment List (80 points)\n",
    "**Make sure you excute every cell in order, and reserve the outputs of every cell.**\n",
    "1. Transform and plot image. (15 points)\n",
    "2. Data loading. (10 points)\n",
    "3. Train the baseline model and plot the learning curve. (15 points)\n",
    "\n",
    "4. Comparison and analysis (20 points)\n",
    "    * Compare the training results of 5, 20, and 50 epochs.\n",
    "    * Use `torch.optim.Adam()` with a learning rate of 0.001 as the optimizer. \n",
    "    * Try a different data_transform function \n",
    "5. Double the number of hidden units in your model and train it for 20 epochs, what happens to the results? (10 points)\n",
    "6. Make a prediction on your own custom image of pizza/steak/sushi (you could even download one from the internet) and share your prediction. (10 points)\n",
    "    * Does the model you trained get it right? \n",
    "    * If not, what do you think you could do to improve it?\n",
    "    \n",
    "## Advanced options (20 points)\n",
    "**Make sure you excute every cell in order, and reserve the outputs of every cell.**\n",
    "- A1: Train a complicated model on the dataset (ResNet18) (10 points) \\\n",
    "    **Remenber to resize the image data and recall dataloader**.\n",
    "- A2: Compare the performance of a simple model (provided by the template) and the complicated model. (5 points)\n",
    "      Plot learning curves in the same figure axes\n",
    "- A3: Usage of git version control (5 points)\n",
    "      Git add, git commit, git log, insert a screenshot within this notebook\n",
    "\n",
    "### Deadline: 11.59 pm 16/01/2023\n",
    "### Submit a rar/zip folder to brightspace under the unit of **Machine Learning for Media Production**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Importing PyTorch and setting up device-agnostic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.13.1+cu117', 'cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Note: this notebook requires torch >= 1.10.0\n",
    "# Setup device-agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.__version__, device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get data\n",
    "[Food101 dataset](https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/) is popular computer vision benchmark as it contains 1000 images of 101 different kinds of foods, totaling 101,000 images (75,750 train and 25,250 test).\n",
    "In this assignment, only 3 classes are used to form a small classification dataset, it contains pizza, steak and sushi.\n",
    "And instead of 1,000 images per class, ervey image class only has 100 images(10%).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/pizza_steak_sushi directory exists.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup path to data folder\n",
    "data_path = Path(\"data/\")\n",
    "image_path = data_path / \"pizza_steak_sushi\"\n",
    "\n",
    "# If the image folder doesn't exist, download it and prepare it... \n",
    "if image_path.is_dir():\n",
    "    print(f\"{image_path} directory exists.\")\n",
    "else:\n",
    "    print(f\"Did not find {image_path} directory, creating one...\")\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Download pizza, steak, sushi data\n",
    "    with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
    "        request = requests.get(\"https://github.com/lizhiqihhh/AIM-MLWorkshop/raw/main/pizza_steak_sushi.zip\")\n",
    "        print(\"Downloading pizza, steak, sushi data...\")\n",
    "        f.write(request.content)\n",
    "\n",
    "    # Unzip pizza, steak, sushi data\n",
    "    with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
    "        print(\"Unzipping pizza, steak, sushi data...\") \n",
    "        zip_ref.extractall(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('data/pizza_steak_sushi/train'),\n",
       " PosixPath('data/pizza_steak_sushi/test'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup train and testing paths\n",
    "train_dir = image_path / \"train\"\n",
    "test_dir = image_path / \"test\"\n",
    "\n",
    "train_dir, test_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "1. Transform training dataset and testing dataset.\n",
    "2. Plot images \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Transforming data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datasets, transforms\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "# import libraries and packages\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write transform for image\n",
    "data_transform = transforms.Compose([\n",
    "    # Step 1: Resize the images to 64x64\n",
    "    # Resize the images to 64x64x3 (64 height, 64 width, 3 color channels)\n",
    "    transforms.Resize((64,64)),\n",
    "    # Step 2: Turn the image into a torch.Tensor\n",
    "    # converts all pixel values from 0-255 to be between 0-1\n",
    "    transforms.ToTensor(),  \n",
    "    # Step 3: RandomHorizontalFlip---Flip the images randomly on the horizontal p = probability of flip, 0.5 = 50% chance()\n",
    "    transforms.RandomHorizontalFlip(p=0.5)\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ImageFolder to create dataset(s)\n",
    "from torchvision import datasets\n",
    "train_data = datasets.ImageFolder(root=train_dir, # root should be the target folder of images\n",
    "                                  transform=data_transform, # transform should be a set of transform functions to perform on images\n",
    "                                  target_transform=None) # transforms to perform on labels (if necessary)\n",
    "\n",
    "test_data = datasets.ImageFolder(root=test_dir, # it should be the folder of test data \n",
    "                                 transform=data_transform) # same with transform applied to train_data\n",
    "\n",
    "print(f\"Train data:\\n{train_data}\\nTest data:\\n{test_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Plot the transformed image\n",
    "`Plot_imgs` and `plot_transformed_images` are defined in plot.py, complete the contents in plot.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from plot import Plot_imgs\n",
    "# Setup path to data folder\n",
    "data_path = Path(\"data/\")\n",
    "image_path = data_path / \"pizza_steak_sushi\"\n",
    "\n",
    "# Plot an image using matplotlib\n",
    "# Please complete the plot.py before use this plotting function\n",
    "Plot_imgs(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot import plot_transformed_images\n",
    "image_path_list = list(image_path.glob(\"*/*/*.jpg\"))\n",
    "plot_transformed_images(image_path_list, \n",
    "                        transform=data_transform, \n",
    "                        n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class names as a list\n",
    "class_names = train_data.classes\n",
    "# Try index on the `train_data` and `test_data` `Dataset`'s to find samples and their target labels.\n",
    "img, label = train_data[0][0], train_data[0][1]\n",
    "# Print the shape/content/datatype of img and label\n",
    "print(f\"img shape: {img.shape} , img datatype : {img.dtype}, \\nimg content: \\n{img}\\n\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "img_permute = img.permute(1, 2, 0)\n",
    "\n",
    "# Print out different shapes (before and after permute)\n",
    "print(f\"Original shape: {img.shape} -> [color_channels, height, width]\")\n",
    "print(f\"Image permute shape: {img_permute.shape} -> [height, width, color_channels]\")\n",
    "\n",
    "\n",
    "# ---------------Plot the permuted image-------------\n",
    "plt.figure()\n",
    "plt.imshow(img_permute)\n",
    "# ---------------End of code------------------------\n",
    "plt.axis(\"off\")\n",
    "plt.title(class_names[label], fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Turn loaded images into `DataLoader`'s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Turn train and test Datasets into DataLoaders (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(dataset=train_data,batch_size=32,shuffle = True) # shuffle training data\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_data,batch_size=32,shuffle = False) # don't usually need to shuffle testing data\n",
    "\n",
    "train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a batch of images in the training dataset\n",
    "img, label = next(iter(train_dataloader))\n",
    "\n",
    "print(f\"Image shape: {img.shape} -> [batch_size, color_channels, height, width]\")\n",
    "print(f\"Label shape: {label.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`display_random_images` is defined in plot.py, please complete the contents in `plot.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display random images from Dataset\n",
    "from plot import display_random_images\n",
    "display_random_images(train_data, \n",
    "                      n=12, \n",
    "                      classes=class_names,\n",
    "                      seed=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 Model_0 training\n",
    "### Task 3.1 Train the baseline model TinyVGG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TinyVGG import TinyVGG # import the model from TinyVGG.py\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# --------------Initialize the TinyVGG model--------------\n",
    "'''\n",
    "    Parameters: input_shape\n",
    "                hidden_units\n",
    "                output_shape\n",
    "'''\n",
    "model_0 = TinyVGG(input_shape=3, hidden_units=10, output_shape=3).to(device) \n",
    "# -------------------  End of code -----------------------\n",
    "\n",
    "model_0 # Print the model info here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get a batch of images and labels from the DataLoader\n",
    "img_batch, label_batch = next(iter(train_dataloader))\n",
    "\n",
    "# 2. Get a single image from the batch and unsqueeze the image so its shape fits the model\n",
    "img_single, label_single = img_batch[0].unsqueeze(dim=0), label_batch[0]\n",
    "print(f\"Single image shape: {img_single.shape}\\n\")\n",
    "\n",
    "# 3. Perform a forward pass on a single image\n",
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    pred = model_0(img_single.to(device))\n",
    "    \n",
    "# 4. Print out what's happening and convert model logits -> pred probs -> pred label\n",
    "print(f\"Output logits:\\n{pred}\\n\")\n",
    "print(f\"Output prediction probabilities:\\n{torch.softmax(pred, dim=1)}\\n\")\n",
    "print(f\"Output prediction label:\\n{torch.argmax(torch.softmax(pred, dim=1), dim=1)}\\n\")\n",
    "print(f\"Actual label:\\n{label_single}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training function from TinyVGG.py\n",
    "from TinyVGG import train\n",
    "# Set random seeds\n",
    "torch.manual_seed(42) \n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# Set number of epochs\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "# Setup loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_0.parameters(), lr=0.001)\n",
    "\n",
    "# Start the timer\n",
    "from timeit import default_timer as timer \n",
    "start_time = timer()\n",
    "\n",
    "# ------------------------- Train model_0 --------------------------\n",
    "# Fill in the parentheses with parameters needed in the train function\n",
    "model_0_results = train(model = model_0, \n",
    "                        train_dataloader = train_dataloader, \n",
    "                        test_dataloader  = test_dataloader, \n",
    "                        optimizer = optimizer,\n",
    "                        loss_fn = loss_fn,\n",
    "                        epochs = NUM_EPOCHS )\n",
    "# -------------------------  End of code  --------------------------\n",
    "# End the timer and print out how long it took\n",
    "end_time = timer()\n",
    "print(f\"Total training time: {end_time-start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.2: Plot the loss curves of Model_0\n",
    "\n",
    "From the print outs of our `model_0` training, it didn't look like it did too well.\n",
    "\n",
    "Create a function to plot the values in the `model_0_results` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Dict, List\n",
    "def plot_loss_curves(results: Dict[str, List[float]]):\n",
    "    \"\"\"Plots training curves of a results dictionary.\n",
    "\n",
    "    Args:\n",
    "        results (dict): dictionary containing list of values, e.g.\n",
    "            {\"train_loss\": [...],\n",
    "             \"train_acc\": [...],\n",
    "             \"test_loss\": [...],\n",
    "             \"test_acc\": [...]}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the loss values of the results dictionary (training and test)\n",
    "    train_loss = results['train_loss']\n",
    "    test_loss = results['test_loss']\n",
    "\n",
    "    # Get the accuracy values of the results dictionary (training and test)\n",
    "    train_accuracy = results['train_acc']\n",
    "    test_accuracy = results['test_acc']\n",
    "\n",
    "    # Figure out how many epochs there were\n",
    "    epochs = range(len(results['train_loss']))\n",
    "\n",
    "    # Setup a plot \n",
    "    plt.figure(figsize=(15, 7))\n",
    "\n",
    "    # --------------- Complete the following lines --------------\n",
    "    # Plot loss, please include label, title, and legend in the figure\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs,train_loss,label=\"Train loss\")   # plot epochs, train_loss\n",
    "    plt.plot(epochs,test_loss, label=\"Test loss\")   # plot epochs, test_loss\n",
    "    plt.title('Train and Test Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend(loc='upper right')\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs,train_accuracy, label=\"Train accuracy\") # plot epochs, train_accuracy, add label\n",
    "    plt.plot(epochs,test_accuracy,label=\"Test accuracy\") # plot epochs, test_accuracy, add label\n",
    "    plt.title('Train and Test Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend(loc='lower right')\n",
    "    # ---------------------- End of codes -----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(model_0_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torchinfo` comes with a `summary()` method that takes a PyTorch model as well as an `input_shape` and returns what happens as a tensor moves through your model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    import torchinfo\n",
    "except:\n",
    "    !pip install torchinfo\n",
    "    import torchinfo\n",
    "    \n",
    "from torchinfo import summary\n",
    "summary(model_0, input_size=[1, 3, 64, 64]) # do a test pass through of an example input size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Comparison and analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.1 Try different epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for 5 epochs\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "# create a new instance of TinyVGG model\n",
    "model_e_5 = TinyVGG(input_shape=3, hidden_units=10, output_shape=3).to(device)\n",
    "\n",
    "loss_fn=nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_e_5.parameters(), lr=0.001)\n",
    "\n",
    "model_e_5_results = train(model= model_e_5,\n",
    "                        train_dataloader= train_dataloader,\n",
    "                        test_dataloader= test_dataloader,\n",
    "                        optimizer= optimizer,\n",
    "                        loss_fn= loss_fn,\n",
    "                        epochs= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for 20 epochs\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "model_e_20 = TinyVGG(input_shape=3, hidden_units=10, output_shape=3).to(device)\n",
    "\n",
    "loss_fn=nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_e_20.parameters(), lr=0.001)\n",
    "\n",
    "model_e_20_results = train(model= model_e_20,\n",
    "                        train_dataloader= train_dataloader,\n",
    "                        test_dataloader= test_dataloader,\n",
    "                        optimizer= optimizer,\n",
    "                        loss_fn= loss_fn,\n",
    "                        epochs= 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for 50 epochs\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "model_e_50 = TinyVGG(input_shape=3, hidden_units=10, output_shape=3).to(device)\n",
    "\n",
    "loss_fn=nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_e_50.parameters(), lr=0.001)\n",
    "\n",
    "model_e_50_results = train(model= model_e_50,\n",
    "                        train_dataloader= train_dataloader,\n",
    "                        test_dataloader= test_dataloader,\n",
    "                        optimizer= optimizer,\n",
    "                        loss_fn= loss_fn,\n",
    "                        epochs= 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare: Print the differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "model_compare_1 = pd.DataFrame(model_e_5_results)\n",
    "model_compare_2 = pd.DataFrame(model_e_20_results)\n",
    "model_compare_3 = pd.DataFrame(model_e_50_results)\n",
    "\n",
    "\n",
    "pd.concat([model_compare_1[4:5],model_compare_2[19:20], model_compare_3[49:50]], keys = ['Model with 5 Epochs', 'Model with 20 Epochs', 'Model with 50 Epochs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis: What you find and how to improve model_0's performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.2 Try different data transform functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "torch.manual_seed(42)\n",
    "# --------- Create training transform with TrivialAugment ---------\n",
    "# TrivialAugment: Tuning-Free Yet State-of-the-Art Data Augmentation (source:https://arxiv.org/abs/2103.10158)\n",
    "train_transform_trivial_augment = transforms.Compose([\n",
    "    # Resize\n",
    "    transforms.Resize(size=(64,64)),\n",
    "\n",
    "    # RandomHorizontalFlip\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "\n",
    "    # TrivialAugment\n",
    "    transforms.TrivialAugmentWide(fill=20),\n",
    "\n",
    "    # ToTensor\n",
    "    transforms.ToTensor()\n",
    "    \n",
    "])\n",
    "\n",
    "train_data_augmented = datasets.ImageFolder(train_dir, transform=train_transform_trivial_augment)\n",
    "\n",
    "train_dataloader_augmented = DataLoader(dataset=train_data_augmented, batch_size=5, shuffle=True)\n",
    "test_dataloader_simple = DataLoader(dataset=test_data,batch_size=5,shuffle = False)\n",
    "# ---------------------- End of code ----------------------\n",
    "\n",
    "train_dataloader_augmented, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model_1 and send it to the target device\n",
    "torch.manual_seed(42)\n",
    "model_1 = TinyVGG(input_shape=3, hidden_units=10, output_shape=3).to(device)\n",
    "model_1 # print model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds\n",
    "torch.manual_seed(42) \n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# Set number of epochs\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "# Setup loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_1.parameters(), lr=0.001)\n",
    "\n",
    "# Start the timer\n",
    "from timeit import default_timer as timer \n",
    "start_time = timer()\n",
    "\n",
    "# ------------------------- Train model_1 ----------------------------\n",
    "# Fill in the parentheses with parameters needed in the train function\n",
    "model_1_results = train(model = model_1,\n",
    "                        train_dataloader = train_dataloader_augmented,\n",
    "                        test_dataloader = test_dataloader_simple,\n",
    "                        optimizer = optimizer,\n",
    "                        loss_fn = loss_fn,\n",
    "                        epochs = NUM_EPOCHS)\n",
    "# ------------------------- End of model_1 ---------------------------\n",
    "# End the timer and print out how long it took\n",
    "end_time = timer()\n",
    "print(f\"Total training time: {end_time-start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Double the number of hidden units in your model and train it for 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double the number of hidden units and train for 20 epochs\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "model_2 = TinyVGG(input_shape=3, hidden_units=20, output_shape=3).to(device) # use 20 hidden units instead of 10\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_2.parameters(), lr=0.001)\n",
    "\n",
    "model_2_results = train(model = model_2, \n",
    "                        train_dataloader = train_dataloader_augmented, \n",
    "                        test_dataloader  = test_dataloader_simple, \n",
    "                        optimizer = optimizer,\n",
    "                        loss_fn = loss_fn,\n",
    "                        epochs = 20) # train for 20 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Make prediction on a custom image based on model_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a custom image from img_path and represent it as a tensor datatype\n",
    "import torchvision\n",
    "\n",
    "img_path = './data/'\n",
    "custom_image = img_path + \"img.jpeg\"\n",
    "img = torchvision.io.read_image(custom_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction on the image, put model_2 in eval mode\n",
    "model_2.eval()\n",
    "with torch.inference_mode():\n",
    "  # Get image pixels into float + between 0 and 1\n",
    "  img = img / 255.\n",
    "  # -------------------- Complete the following lines ---------------------\n",
    "  # Resize image to 64x64\n",
    "  resize = transforms.Resize(size=(64,64))\n",
    "  img = resize(img)\n",
    "  print('Resized image shape: \\n',img.shape)\n",
    "  # Turn image in single batch and pass to target device\n",
    "  # add an additional dimension to img using unsqueeze()\n",
    "  batch_img = img.unsqueeze(0).to(device) # modify this line!!!\n",
    "  print('Add batch dim: \\n', batch_img.shape)\n",
    "  # Predict on image\n",
    "  y_pred_logit = model_2(batch_img) \n",
    "  # ---------------------   End of code    ------------------------------\n",
    "  # Convert pred logit to pred label\n",
    "  pred_label = torch.argmax(y_pred_logit, dim=1)\n",
    "\n",
    "# Plot the image and prediction\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "plt.title(f\"Pred label: {class_names[pred_label]}\")\n",
    "plt.axis(False)\n",
    "     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "Does the model you trained get it right?\n",
    "If not, how to improve it?\\\n",
    "**Your answer:\n",
    "\n",
    "The trained model is providing wrong predictions on new images.The image of a sushi is being identified as pizza by the model. This was tested on few other images as well where the trained model predicted all incorrect labels.\n",
    "\n",
    "\n",
    "\n",
    "To improve the prediction accuracy the following can be done:\n",
    "\n",
    "1. Increase the number of datasets for each label used for training.\n",
    "2. Train the mdoel with optimum number of epochs using early stopping.\n",
    "3. \n",
    "\n",
    "**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced tasks\n",
    "### A1: Train a complicated model (Use ResNet18 as an example) (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read `Resnet18_pytorch.py` and complete the model file\n",
    "> If you finish `Resnet18_pytorch.py` correctly, run the following line will generate a vector with shape = ([1,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python3.9 Resnet18_pytorch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Resnet18_pytorch import ResNet, BasicBlock\n",
    "torch.manual_seed(42)\n",
    "model_resnet = ResNet(img_channels=3, num_layers=18, block=BasicBlock, num_classes=3).to(device)\n",
    "model_resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing train dataloader and test dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32\n",
    "NUM_WORKERS=2\n",
    "# ----- Complete the following transform functions -----\n",
    "train_transform_augment = transforms.Compose([\n",
    "\n",
    "    # Resize\n",
    "    transforms.Resize(size=(64,64)),\n",
    "\n",
    "    # RandomHorizontalFlip\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "\n",
    "    # TrivialAugment\n",
    "    transforms.TrivialAugmentWide(fill=20),\n",
    "\n",
    "    # ToTensor\n",
    "    transforms.ToTensor()\n",
    "    \n",
    "])\n",
    "   \n",
    "#  ----------------  End of code --------------------\n",
    "train_data_augmented = datasets.ImageFolder(train_dir, transform=train_transform_augment)\n",
    "train_dataloader_resnet = DataLoader(dataset=train_data_augmented,batch_size=5,shuffle = True)\n",
    "\n",
    "test_dataloader_simple = DataLoader(dataset=test_data,batch_size=5,shuffle = False)\n",
    "\n",
    "train_dataloader_resnet, test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds\n",
    "torch.manual_seed(42) \n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# Set number of epochs\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "# Setup loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_1.parameters(), lr=0.001)\n",
    "\n",
    "# Start the timer\n",
    "from timeit import default_timer as timer \n",
    "start_time = timer()\n",
    "\n",
    "# Train model\n",
    "model_resnet_results = train(model = model_resnet, \n",
    "                        train_dataloader = train_dataloader_resnet, \n",
    "                        test_dataloader  = test_dataloader_simple, \n",
    "                        optimizer = optimizer,\n",
    "                        loss_fn = loss_fn,\n",
    "                        epochs = NUM_EPOCHS)\n",
    "\n",
    "# End the timer and print out how long it took\n",
    "end_time = timer()\n",
    "print(f\"Total training time: {end_time-start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A2: Compare model performance (5 points)\n",
    "Choose a previous model used in **Task 3** (model_0) or **Task 4** (model_1) to compare with ResNet18 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "summary(model_resnet, input_size=[1, 3, 224, 224]) # do a test pass through of an example input size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the train_loss and test_loss of model_resnet and a previous model using subplot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "model_0_df = pd.DataFrame(model_0_results) # Or model_1\n",
    "\n",
    "model_resnet_df = pd.DataFrame(model_resnet_results)\n",
    "model_0_df, model_resnet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ Complete subplot functions in the following lines -------\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Get number of epochs\n",
    "epochs = range(len(model_0_df))\n",
    "\n",
    "# Plot train loss with label, title, legend\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(epochs,model_0_df['train_loss'])   # plot epochs, train_loss\n",
    "plt.plot(epochs,model_resnet_df['train_loss'])   # plot epochs, test_loss\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend([\"Tiny VGG model\", \"Resnet model\"],loc='upper right')\n",
    "\n",
    "# Plot test loss\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epochs,model_0_df['test_loss'])   # plot epochs, train_loss\n",
    "plt.plot(epochs,model_resnet_df['test_loss'])   # plot epochs, test_loss\n",
    "plt.title('Test Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend([\"Tiny VGG model\", \"Resnet model\"],loc='upper right')\n",
    "\n",
    "# Plot train accuracy\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(epochs,model_0_df['train_acc'])   # plot epochs, train_loss\n",
    "plt.plot(epochs,model_resnet_df['train_acc'])   # plot epochs, test_loss\n",
    "plt.title('Train Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend([\"Tiny VGG model\", \"Resnet model\"],loc='upper right')\n",
    " \n",
    "# Plot test accuracy\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(epochs,model_0_df['test_acc'])   # plot epochs, train_loss\n",
    "plt.plot(epochs,model_resnet_df['test_acc'])   # plot epochs, test_loss\n",
    "plt.title('Test Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend([\"Tiny VGG model\", \"Resnet model\"],loc='upper right')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A3: Git version control (5 points)\n",
    "Please insert an image in the cell to show your git log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Git version control advices\n",
    "1. Create a remote repo, upload this notebote to the repo\\\n",
    "   **Take a screenshot of the inital status**\n",
    "2. git clone (ssh link of the repo)\n",
    "3. Make some modifications to the files\n",
    "4. git add .\n",
    "5. git commit -m \"leave some message here\"\n",
    "6. git push\n",
    "7. git log\n",
    "8. check the remote repo, **Take a screenshot after git push operations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"./git-staging-workflow.png\",width=900,height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"git pull.png\",width=994,height=655)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"git merge.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"git push steps.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"before.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"after.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"gitlog.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
